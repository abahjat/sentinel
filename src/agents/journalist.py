import os
from datetime import datetime
from src.state import AgentState

class JournalistAgent:
    def __init__(self):
        self.output_dir = "Daily_Briefings"
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

    def write_report(self, screened_artifacts, all_raw_artifacts) -> str:
        # Note: Papers are now marked as processed in monitor_node immediately after fetch
        # This prevents race conditions when running multiple times

        if not screened_artifacts:
            return "No relevant papers found today."

        # Deduplicate artifacts as a safety net (in case of any upstream issues)
        seen_ids = set()
        unique_artifacts = []
        for art in screened_artifacts:
            if art['id'] not in seen_ids:
                seen_ids.add(art['id'])
                unique_artifacts.append(art)
        
        if len(unique_artifacts) < len(screened_artifacts):
            print(f"ðŸ“° Journalist: Removed {len(screened_artifacts) - len(unique_artifacts)} duplicate entries.")

        date_str = datetime.now().strftime("%Y-%m-%d")
        filename = f"{self.output_dir}/Briefing_{date_str}.md"
        
        total_found = len(unique_artifacts)
        code_avail = sum(1 for a in unique_artifacts if a.get('code_link'))
        
        md_content = f"""# ðŸ›¡ï¸ Sentinel Briefing: {date_str}

**Status:** {total_found} High-Signal Papers | ðŸ’» {code_avail} Repos Found
**Focus:** LegalTech, GenAI, Enterprise Architecture, Forensics

---

## ðŸš¨ Top Priority Radar
"""
        sorted_artifacts = sorted(unique_artifacts, key=lambda x: x['score'], reverse=True)

        for art in sorted_artifacts:
            icon = "ðŸŸ¢" if art['score'] >= 9 else "ðŸŸ¡"
            code_badge = f" [ðŸ’» CODE AVAILABLE]({art['code_link']})" if art.get('code_link') else ""
            
            md_content += f"""
### {icon} [{art['score']}/10] {art['title']}
* **Category:** `{art['category']}`
* **Why it matters:** {art['relevance_reason']}
* **Tech Depth:** {art.get('technical_depth', 'N/A')} {code_badge}

> **Abstract:** {art['summary']}

[View PDF]({art['source_url']}) | [ArXiv ID: {art['id']}]
"""
            if art.get('code_link'):
                md_content += f"\n**ðŸ”— Official Repo:** `{art['code_link']}`\n"
            
            md_content += "\n---\n"

        md_content += f"\n*Generated by Sentinel Agentic System on {datetime.now().strftime('%H:%M:%S')}*"

        with open(filename, "w", encoding="utf-8") as f:
            f.write(md_content)
            
        print(f"ðŸ“° Journalist: Briefing saved to {filename}")
        return f"Report generated at {filename}"

# LangGraph Node Wrapper
def journalist_node(state: AgentState):
    journalist = JournalistAgent()
    
    # We retrieve both lists from State
    screened = state.get('screened_artifacts', [])
    raw = state.get('raw_artifacts', []) # Needed for memory
    
    report_path = journalist.write_report(screened, raw)
    return {"final_digest": report_path}